{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "\n",
    "data = pd.read_csv('../data/ERP_data.csv')\n",
    "labels = list(data.columns.values)\n",
    "del labels[0]\n",
    "del labels[0]\n",
    "\n",
    "targets = data['Phenotype']\n",
    "del data['Subject']\n",
    "del data['Phenotype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, feature_selection, cross_validation, ensemble\n",
    "\n",
    "folds = 10\n",
    "\n",
    "imp = preprocessing.Imputer()\n",
    "data = imp.fit_transform(data, targets)\n",
    "data = preprocessing.scale(data)\n",
    "data = feature_selection.SelectKBest(feature_selection.f_classif, k=22).fit_transform(data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.698467336683417, with std: 0.012992622412959138\n",
      "Precision: 0.6799164394878185\n",
      "Recall: 0.7445959595959596\n",
      "F1 Score: 0.7107066830258613\n",
      "Confusion Matrix:\n",
      "   HC     AD\n",
      "[[ 65.28   34.72 ]\n",
      " [ 25.285  73.715]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import discriminant_analysis, metrics\n",
    "\n",
    "clf = discriminant_analysis.LinearDiscriminantAnalysis(solver='eigen', shrinkage=0.2)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "confusions = []\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for i in range(200):\n",
    "    cross_val = cross_validation.StratifiedKFold(targets, n_folds=folds, shuffle=True)\n",
    "    preds = cross_validation.cross_val_predict(clf, data, targets, cv=cross_val)\n",
    "    accuracy = metrics.accuracy_score(targets, preds)\n",
    "    precision, recall, fscore, support = metrics.precision_recall_fscore_support(\n",
    "        targets, preds, average='binary', pos_label='AD')\n",
    "    confusion = metrics.confusion_matrix(targets, preds, labels=['HC', 'AD'])\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    fscores.append(fscore)\n",
    "    confusions.append(confusion)\n",
    "\n",
    "print(\"Accuracy: {0}, with std: {1}\".format(np.mean(accuracies), np.std(accuracies)))\n",
    "print(\"Precision: {0}\".format(np.mean(precisions)))\n",
    "print(\"Recall: {0}\".format(np.mean(recalls)))\n",
    "print(\"F1 Score: {0}\".format(np.mean(fscores)))\n",
    "print(\"Confusion Matrix:\\n   HC     AD\\n{0}\".format(np.mean(confusions, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.669070351758794, with std: 0.01316542156720767\n",
      "Precision: 0.6545137016986528\n",
      "Recall: 0.7094949494949495\n",
      "F1 Score: 0.6808139792167469\n",
      "Confusion Matrix:\n",
      "   HC     AD\n",
      "[[ 62.905  37.095]\n",
      " [ 28.76   70.24 ]]\n"
     ]
    }
   ],
   "source": [
    "clf = discriminant_analysis.QuadraticDiscriminantAnalysis(reg_param=0.3)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "confusions = []\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for i in range(200):\n",
    "    cross_val = cross_validation.StratifiedKFold(targets, n_folds=folds, shuffle=True)\n",
    "    preds = cross_validation.cross_val_predict(clf, data, targets, cv=cross_val)\n",
    "    accuracy = metrics.accuracy_score(targets, preds)\n",
    "    precision, recall, fscore, support = metrics.precision_recall_fscore_support(\n",
    "        targets, preds, average='binary', pos_label='AD')\n",
    "    confusion = metrics.confusion_matrix(targets, preds, labels=['HC', 'AD'])\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    fscores.append(fscore)\n",
    "    confusions.append(confusion)\n",
    "\n",
    "print(\"Accuracy: {0}, with std: {1}\".format(np.mean(accuracies), np.std(accuracies)))\n",
    "print(\"Precision: {0}\".format(np.mean(precisions)))\n",
    "print(\"Recall: {0}\".format(np.mean(recalls)))\n",
    "print(\"F1 Score: {0}\".format(np.mean(fscores)))\n",
    "print(\"Confusion Matrix:\\n   HC     AD\\n{0}\".format(np.mean(confusions, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
