{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "data = pd.read_csv('../data/ERP_data.csv')\n",
    "labels = list(data.columns.values)\n",
    "del labels[0]\n",
    "del labels[0]\n",
    "\n",
    "targets = data['Phenotype']\n",
    "del data['Subject']\n",
    "del data['Phenotype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import feature_selection\n",
    "from sklearn import cross_validation\n",
    "\n",
    "folds = 10\n",
    "\n",
    "imp = preprocessing.Imputer()\n",
    "data = imp.fit_transform(data, targets)\n",
    "data = preprocessing.scale(data)\n",
    "anova_selection_logreg = feature_selection.SelectKBest(feature_selection.f_classif, k=21)\n",
    "anova_selection_svm = feature_selection.SelectKBest(feature_selection.f_classif, k=16)\n",
    "anova_selection_neighbors = feature_selection.SelectKBest(feature_selection.f_classif, k=22)\n",
    "anova_selection_rf = feature_selection.SelectKBest(feature_selection.f_classif, k=11)\n",
    "anova_selection_gboost = feature_selection.SelectKBest(feature_selection.f_classif, k=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'AD'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1da557c7035f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mpred_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpipes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0my_truth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0my_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_logreg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_truth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64, \n\u001b[1;32m-> 1142\u001b[1;33m                          order=\"C\")\n\u001b[0m\u001b[0;32m   1143\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    371\u001b[0m                                       force_all_finite)\n\u001b[0;32m    372\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'AD'"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model, svm, neighbors, ensemble\n",
    "from sklearn import pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg_model = linear_model.LogisticRegression(C=.001)\n",
    "svm_model = svm.SVC(C=0.66)\n",
    "neighbors_model = neighbors.KNeighborsClassifier(n_neighbors=13)\n",
    "rf_model = ensemble.RandomForestClassifier(n_estimators=20, min_samples_split=3, min_samples_leaf=2)\n",
    "gboost_model = ensemble.GradientBoostingClassifier(min_samples_split=35, learning_rate=0.5, n_estimators=110)\n",
    "stack_logreg_model = linear_model.LogisticRegression(C=1)\n",
    "'''\n",
    "logreg_pipe = pipeline.make_pipeline(anova_selection_logreg, logreg_model)\n",
    "svm_pipe = pipeline.make_pipeline(anova_selection_svm, svm_model)\n",
    "neighbors_pipe = pipeline.make_pipeline(anova_selection_neighbors, neighbors_model)\n",
    "rf_pipe = pipeline.make_pipeline(anova_selection_rf, rf_model)\n",
    "gboost_pipe = pipeline.make_pipeline(anova_selection_gboost, gboost_model)\n",
    "'''\n",
    "pipes = []\n",
    "pipes.append(pipeline.make_pipeline(anova_selection_logreg, logreg_model))\n",
    "pipes.append(pipeline.make_pipeline(anova_selection_svm, svm_model))\n",
    "pipes.append(pipeline.make_pipeline(anova_selection_neighbors, neighbors_model))\n",
    "pipes.append(pipeline.make_pipeline(anova_selection_rf, rf_model))\n",
    "pipes.append(pipeline.make_pipeline(anova_selection_gboost, gboost_model))\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "confusions = []\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for i in range(1):\n",
    "    cross_val = cross_validation.StratifiedKFold(targets, n_folds=folds, shuffle=True)\n",
    "    y_truth = []\n",
    "    y_preds = []\n",
    "    for train, test in cross_val:\n",
    "        X_train, X_test, y_train, y_test = data[train], data[test], targets[train], targets[test]\n",
    "        pred_features = np.transpose([clf.fit(X_train, y_train).predict(data) for clf in pipes])\n",
    "        y_truth.append(y_test)\n",
    "        y_preds.append(stack_logreg_model.fit(pred_features[train], y_train).predict(pred_features[test]))\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_truth, preds)\n",
    "    precision, recall, fscore, support = metrics.precision_recall_fscore_support(\n",
    "        y_truth, preds, average='binary', pos_label='AD')\n",
    "    confusion = metrics.confusion_matrix(y_truth, preds, labels=['HC', 'AD'])\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    fscores.append(fscore)\n",
    "    confusions.append(confusion)\n",
    "\n",
    "print(\"Accuracy: {0}, with std: {1}\".format(np.mean(accuracies), np.std(accuracies)))\n",
    "print(\"Precision: {0}\".format(np.mean(precisions)))\n",
    "print(\"Recall: {0}\".format(np.mean(recalls)))\n",
    "print(\"F1 Score: {0}\".format(np.mean(fscores)))\n",
    "print(\"Confusion Matrix:\\n   HC     AD\\n{0}\".format(np.mean(confusions, axis=0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
