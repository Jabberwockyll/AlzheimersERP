{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "data = pd.read_csv('../data/ERP_data.csv')\n",
    "labels = list(data.columns.values)\n",
    "del labels[0]\n",
    "del labels[0]\n",
    "\n",
    "targets = data['Phenotype']\n",
    "del data['Subject']\n",
    "del data['Phenotype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import feature_selection\n",
    "from sklearn import cross_validation\n",
    "\n",
    "folds = 10\n",
    "\n",
    "imp = preprocessing.Imputer()\n",
    "data = imp.fit_transform(data, targets)\n",
    "data = preprocessing.scale(data)\n",
    "anova_selection_logreg = feature_selection.SelectKBest(feature_selection.f_classif, k=21)\n",
    "anova_selection_svm = feature_selection.SelectKBest(feature_selection.f_classif, k=16)\n",
    "anova_selection_neighbors = feature_selection.SelectKBest(feature_selection.f_classif, k=22)\n",
    "anova_selection_rf = feature_selection.SelectKBest(feature_selection.f_classif, k=11)\n",
    "anova_selection_gboost = feature_selection.SelectKBest(feature_selection.f_classif, k=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6856532663316582, with std: 0.024186976831265118\n",
      "Precision: 0.7160774065244155\n",
      "Recall: 0.6111616161616162\n",
      "F1 Score: 0.6589781958656528\n",
      "Confusion Matrix:\n",
      "   HC     AD\n",
      "[[ 75.94   24.06 ]\n",
      " [ 38.495  60.505]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model, svm, neighbors, ensemble, naive_bayes\n",
    "from sklearn import pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg_model = linear_model.LogisticRegression(C=.001)\n",
    "svm_model = svm.SVC(C=0.66)\n",
    "neighbors_model = neighbors.KNeighborsClassifier(n_neighbors=13)\n",
    "naive_bayes_model = naive_bayes.GaussianNB()\n",
    "rf_model = ensemble.RandomForestClassifier(n_estimators=20, min_samples_split=3, min_samples_leaf=2)\n",
    "gboost_model = ensemble.GradientBoostingClassifier(min_samples_split=35, learning_rate=0.5, n_estimators=110)\n",
    "stack_logreg_model = linear_model.LogisticRegression(C=0.1)\n",
    "stack_gboost_model = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "pipes = []\n",
    "pipes.append(pipeline.make_pipeline(anova_selection_logreg, logreg_model))\n",
    "pipes.append(pipeline.make_pipeline(anova_selection_svm, svm_model))\n",
    "pipes.append(pipeline.make_pipeline(anova_selection_neighbors, neighbors_model))\n",
    "pipes.append(pipeline.make_pipeline(anova_selection_neighbors, naive_bayes_model))\n",
    "pipes.append(pipeline.make_pipeline(anova_selection_rf, rf_model))\n",
    "pipes.append(pipeline.make_pipeline(anova_selection_gboost, gboost_model))\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "confusions = []\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for i in range(200):\n",
    "    cross_val = cross_validation.StratifiedKFold(targets, n_folds=folds, shuffle=True)\n",
    "    y_truth = []\n",
    "    y_preds = []\n",
    "    for train, test in cross_val:\n",
    "        X_train, y_train, y_test = data[train], targets[train], targets[test]\n",
    "        pred_features = np.transpose([le.fit_transform(clf.fit(X_train, y_train).predict(data)) for clf in pipes])\n",
    "        y_truth.extend(y_test)\n",
    "        preds = stack_logreg_model.fit(pred_features[train], y_train).predict(pred_features[test])\n",
    "        y_preds.extend(preds)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_truth, y_preds)\n",
    "    precision, recall, fscore, support = metrics.precision_recall_fscore_support(\n",
    "        y_truth, y_preds, average='binary', pos_label='AD')\n",
    "    confusion = metrics.confusion_matrix(y_truth, y_preds, labels=['HC', 'AD'])\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    fscores.append(fscore)\n",
    "    confusions.append(confusion)\n",
    "\n",
    "print(\"Accuracy: {0}, with std: {1}\".format(np.mean(accuracies), np.std(accuracies)))\n",
    "print(\"Precision: {0}\".format(np.mean(precisions)))\n",
    "print(\"Recall: {0}\".format(np.mean(recalls)))\n",
    "print(\"F1 Score: {0}\".format(np.mean(fscores)))\n",
    "print(\"Confusion Matrix:\\n   HC     AD\\n{0}\".format(np.mean(confusions, axis=0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
